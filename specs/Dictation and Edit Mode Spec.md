# Dictation and Edit Mode Design Specification

## Overview

In addition to voice commands, we also want to have other two modes: 
1. **Dictation Mode** - Long-form speech-to-text transcription
2. **Edit Mode** - AI-powered text editing via voice instructions

Both modes use explicit start/stop control (no automatic silence detection) and leverage OpenAI's Whisper API for transcription and GPT-4 for text transformation.

## User Interface

### HUD Design

The HUD will display two primary action buttons when idle, in addition to the Voice Commands button:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ™ï¸ VoiceControl                        â”‚
â”‚                                         â”‚
â”‚  [ğŸ“ Dictation]  [âœï¸ Edit]             â”‚
â”‚   âŒ¥âŒ˜D           âŒ¥âŒ˜E                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual States (Make them compatible with Voice commands HUD states)

1. **Idle State**: Shows two buttons with hotkey hints
2. **Recording State**: Shows recording indicator, elapsed time, stop button
3. **Processing State**: Shows progress indicator while transcribing/processing
4. **Error State**: Shows error message with retry option

## Dictation Mode

### Workflow

1. **Start Recording**
   - User presses âŒ¥âŒ˜D or clicks Dictation button
   - AudioEngine starts recording (no silence detection)
   - HUD shows recording state with elapsed time
   - Maximum recording duration: 10 minutes

2. **Stop Recording**
   - User presses âŒ¥âŒ˜D again or clicks Stop button
   - Recording stops immediately
   - Audio data sent to Whisper API

3. **Transcription**
   - HUD shows processing state
   - Whisper returns transcribed text
   - Send text to GPT 4.1 mini with a simple prompt to lightly format the dictated text without changing anything of substance. (add a flag to be able to turn this off)
   - Text is inserted at current cursor position

4. **Cancellation**
   - Press Esc or click X to cancel recording
   - No transcription performed
   - Returns to idle state

### Technical Implementation

```swift
// DictationManager states
enum DictationState {
    case idle
    case recording(startTime: Date)
    case processing
    case error(Error)
}

// Key methods
func startDictation()
func stopDictation()
func cancelDictation()
```

## Edit Mode

### Workflow

1. **Check Selection**
   - User presses âŒ¥âŒ˜E or clicks Edit button
   - System checks for selected text via AccessibilityBridge
   - If no selection: automatically select current paragraph
   - Store selected text and position

2. **Record Instructions**
   - Start recording voice instructions
   - HUD shows recording state with selected text preview
   - User speaks editing instructions

3. **Stop and Process**
   - User presses âŒ¥âŒ˜E again or clicks Stop
   - Recording stops
   - Audio sent to Whisper for transcription

4. **AI Processing**
   - Prompt + Transcribed instructions + selected text sent to GPT-4.1-mini
   - Custom prompt instructs GPT to edit the text
   - Returns edited version

5. **Text Replacement**
   - Find and replace original text with edited version
   - Maintain cursor position
   - Show success feedback

### GPT Prompt Template

```
You are tasked with correcting dictation errors from speech-to-text output. The correction instructions you receive are also dictated and may contain errors.
	â€¢	Only apply corrections that the user explicitly requests (for example, fixing a specific word or phrase that was transcribed incorrectly).
	â€¢	Do not change form, style, arrangement, punctuation, or any other aspect of the text unless it directly addresses a dictation error mentioned by the user.
	â€¢	When the user wants to correct spelling, they will say â€œspelledâ€¦â€ followed by example words that start with each letter. For instance, â€œspelled: Apple, Dog, Catâ€ means the intended letters are â€œA,â€ â€œD,â€ and â€œC.â€ There will be no explicit â€œend spellingâ€ cue, so infer when the spelling sequence stops.

Do not make any additions or stylistic edits beyond the exact dictation corrections the user specifies.

Original message: " 
i was walking threw the park with my dog charley when we saw mr thompson or maybe mrs thomson i cant remember then dumbass and suresh showed up they said something about checking out the new diner downtown charly barked at a squirrel and almost pulled the leesh out of my hand kind of annoying cause i just bought it last weak dumbass also said the train was late again
"

Edit prompt: "can you fix this up itâ€™s not dumbass itâ€™s a spanish name spelled tomato or mom alter serve and itâ€™s not suresh itâ€™s spelled sample under radio alter jersey also fix the wrong words like threw which makes no sense in that context same with weak and add punctuation where it makes sense and split up the run-ons thanks. Capitalize sentence starts please"

Output the corrected_message as a a json property. 
```

## Error Handling

### Recording Errors
- Microphone permission denied â†’ Show settings instructions
- Recording failure â†’ Offer retry
- Maximum duration exceeded â†’ Auto-stop and process

### API Errors
- Network timeout â†’ Show offline message
- API rate limit â†’ Show cooldown message
- Invalid API key â†’ Show configuration instructions

### Text Manipulation Errors
- No accessible text field â†’ Show helpful message
- Selection failed â†’ Fallback to manual selection prompt
- Replacement failed â†’ Show error with original text preserved

## HUD State Transitions

### Dictation Mode
```
Idle â†’ Recording â†’ Processing â†’ Idle
 â†“         â†“           â†“
Error â† Cancel â† Network Error
```

### Edit Mode
```
Idle â†’ Selecting â†’ Recording â†’ Processing â†’ Replacing â†’ Idle
 â†“         â†“           â†“            â†“            â†“
Error â† Cancel â† Cancel â† API Error â† Replace Error
```

## Implementation Plan - Edit Mode

### Phase 1: Core Infrastructure Setup
1. **Create EditManager.swift** âœ…
   - Define EditState enum (idle, selecting, recording, processing, replacing, error) âœ…
   - Implement state management similar to CommandManager âœ…
   - Add properties for selected text storage and cursor position âœ…

2. **Update Config.swift** âœ…
   - Add Edit Mode hotkey configuration (âŒ¥âŒ˜E) âœ…
   - Add GPT API configuration (model, max tokens, temperature) âœ…
   - Add Edit Mode specific settings (auto-select paragraph, max recording duration) âœ…

3. **Create GPTService.swift** âœ…
   - Implement OpenAI GPT API integration âœ…
   - Create edit prompt template method âœ…
   - Handle JSON response parsing for corrected text âœ…
   - Add error handling for API failures âœ…

### Phase 2: Text Selection Enhancement
1. **Enhance AccessibilityBridge.swift** âœ…
   - Add `hasTextSelection()` method to check if text is currently selected âœ…
   - Add `selectParagraphIfNoSelection()` method that uses existing `selectParagraph()` âœ…
   - Enhance `getCurrentSelection()` to store original text for later verification âœ…
   - Add `replaceText(originalText:newText:)` method for smart replacement âœ…
   - Handle edge cases (text changed during editing, multiple matches) âœ…

### Phase 3: HUD Integration
1. **Update CommandHUD.swift** âœ…
   - Add Edit Mode button to idle state âœ…
   - Create recording state UI for Edit Mode âœ…
   - Add selected text preview display âœ…
   - Implement processing state with appropriate messaging âœ…

2. **Create EditModeHUD.swift** âœ…
   - Build dedicated view for Edit Mode states âœ…
   - Show selected text preview during recording âœ…
   - Display processing status and error messages âœ…
   - Add cancel functionality with Esc key support âœ…

### Phase 4: Audio Recording Integration
1. **Update AudioEngine.swift** âœ…
   - Add Edit Mode recording configuration (no silence detection) âœ…
   - Implement maximum duration enforcement (10 minutes) âœ…
   - Add recording state callbacks for UI updates âœ…

2. **Update HotkeyManager.swift** âœ…
   - Register âŒ¥âŒ˜E hotkey for Edit Mode âœ…
   - Handle toggle behavior (start/stop with same key) âœ…
   - Coordinate with EditManager for state transitions âœ…

### Phase 5: Workflow Implementation
1. **Implement EditManager Workflow** âœ…
   - startEditing(): Check selection, auto-select if needed, start recording âœ…
   - stopEditing(): Stop recording, transcribe, process with GPT âœ…
   - cancelEditing(): Clean up state, restore UI âœ…
   - processEditingInstructions(): Coordinate Whisper â†’ GPT â†’ Replace flow âœ…

2. **Error Handling** âœ…
   - Handle no accessible text field scenarios âœ…
   - Manage API failures with user-friendly messages âœ…
   - Implement retry mechanisms where appropriate âœ…
   - Preserve original text on failure âœ…

2. **Update HUD for Dictation**
   - Add Dictation button
   - Implement dictation-specific recording view
   - Share processing states with Edit Mode